{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"S&P 500 Governance and Fundamentals Panel with BoardEx Integration\"\n",
        "format: html\n",
        "jupyter: regression_env\n",
        "---\n",
        "\n",
        "::: {.callout-note title=\"Notebook Summary\"}\n",
        "This Quarto notebook constructs a reproducible 20-year panel of S&P 500 companies using point-in-time data from Refinitiv, Compustat, and BoardEx via the WRDS Cloud JupyterHub. The panel includes financial metrics, governance attributes, and director-level diversity indicators.\n",
        ":::\n",
        "\n",
        "## Setup and Refinitiv Universe\n",
        "\n",
        "``` python\n",
        "import wrds\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Connect to WRDS\n",
        "db = wrds.Connection()\n",
        "\n",
        "# Load Refinitiv tickers (point-in-time universe)\n",
        "with open(\"/mnt/data/refinitiv_unique_tickers.json\", \"r\") as f:\n",
        "    refinitiv_tickers = set(t.upper() for t in json.load(f)[\"tickers\"])\n",
        "```\n",
        "\n",
        "## Step 1: Link BoardEx and Compustat\n",
        "\n",
        "``` python\n",
        "link_table = db.raw_sql(\"\"\"\n",
        "    SELECT DISTINCT companyid, gvkey, permco\n",
        "    FROM wrdsapps_link_crsp_comp_bdx.bdxcrspcomplink\n",
        "    WHERE gvkey IS NOT NULL AND permco IS NOT NULL AND preferred = 1 AND duplicate = 0\n",
        "\"\"\")\n",
        "```\n",
        "\n",
        "## Step 2: Get Compustat Company Tickers\n",
        "\n",
        "``` python\n",
        "compustat_info = db.raw_sql(\"\"\"\n",
        "    SELECT gvkey, iid, tic AS ticker\n",
        "    FROM comp.security\n",
        "    WHERE iid = '01'\n",
        "\"\"\")\n",
        "compustat_info[\"ticker\"] = compustat_info[\"ticker\"].str.upper()\n",
        "compustat_info = compustat_info[compustat_info[\"ticker\"].isin(refinitiv_tickers)]\n",
        "\n",
        "link_table = link_table.merge(compustat_info, on=\"gvkey\", how=\"inner\")\n",
        "```\n",
        "\n",
        "## Step 3: BoardEx Board Characteristics\n",
        "\n",
        "``` python\n",
        "boardex = db.raw_sql(\"\"\"\n",
        "    SELECT boardid AS companyid, annualreportdate, numberdirectors, genderratio, stdevage\n",
        "    FROM boardex.na_board_characteristics\n",
        "    WHERE numberdirectors IS NOT NULL AND genderratio IS NOT NULL\n",
        "\"\"\")\n",
        "\n",
        "boardex = boardex[boardex[\"annualreportdate\"] != \"9000-01-01\"]\n",
        "boardex[\"annualreportdate\"] = pd.to_datetime(boardex[\"annualreportdate\"], errors=\"coerce\")\n",
        "boardex[\"fiscal_year\"] = boardex[\"annualreportdate\"].dt.year\n",
        "boardex[\"pct_female_directors\"] = 1 - boardex[\"genderratio\"]\n",
        "boardex[\"estimated_num_female_directors\"] = (boardex[\"numberdirectors\"] * boardex[\"pct_female_directors\"]).round(2)\n",
        "```\n",
        "\n",
        "## Step 4: Compustat Financials\n",
        "\n",
        "``` python\n",
        "comp = db.raw_sql(\"\"\"\n",
        "    SELECT gvkey, datadate, fyear, at, lt, ceq, act, lct, ni, dltt, pstk, csho, prcc_f\n",
        "    FROM comp.funda\n",
        "    WHERE datadate >= '2003-01-01'\n",
        "      AND indfmt = 'INDL' AND datafmt = 'STD' AND popsrc = 'D' AND consol = 'C'\n",
        "\"\"\")\n",
        "\n",
        "comp[\"tobins_q\"] = (comp[\"prcc_f\"] * comp[\"csho\"] + comp[\"at\"] - comp[\"ceq\"]) / comp[\"at\"]\n",
        "comp[\"liquidity_ratio\"] = comp[\"act\"] / comp[\"lct\"]\n",
        "comp[\"leverage_ratio\"] = comp[\"dltt\"] / comp[\"at\"]\n",
        "comp[\"roa\"] = comp[\"ni\"] / comp[\"at\"]\n",
        "\n",
        "comp_funda = comp[[\"gvkey\", \"fyear\", \"tobins_q\", \"liquidity_ratio\", \"leverage_ratio\", \"roa\"]]\n",
        "```\n",
        "\n",
        "## Step 5: Director-Level Diversity Aggregation\n",
        "\n",
        "``` python\n",
        "# Load panel for filtering\n",
        "panel = link_table[[\"companyid\"]].drop_duplicates()\n",
        "\n",
        "print(\"Loading employment records...\")\n",
        "employment = db.raw_sql(\"\"\"\n",
        "    SELECT directorid, companyid, datestartrole AS emp_start, dateendrole AS emp_end\n",
        "    FROM boardex.na_dir_profile_emp\n",
        "    WHERE datestartrole IS NOT NULL\n",
        "\"\"\")\n",
        "\n",
        "employment[\"emp_start\"] = pd.to_datetime(employment[\"emp_start\"], errors=\"coerce\")\n",
        "employment[\"emp_end\"] = pd.to_datetime(employment[\"emp_end\"], errors=\"coerce\")\n",
        "employment[\"fiscal_year\"] = employment[\"emp_start\"].dt.year\n",
        "\n",
        "filtered_emp = employment.merge(panel, on=\"companyid\", how=\"inner\")\n",
        "\n",
        "unique_directors = filtered_emp[\"directorid\"].unique().tolist()\n",
        "chunksize = 1000\n",
        "profile_chunks = []\n",
        "\n",
        "for i in range(0, len(unique_directors), chunksize):\n",
        "    ids_chunk = unique_directors[i:i+chunksize]\n",
        "    id_list_str = \",\".join([f\"'{d}'\" for d in ids_chunk])\n",
        "    query = f\"\"\"\n",
        "        SELECT directorid, gender, dob AS dateofbirth\n",
        "        FROM boardex.na_dir_profile_details\n",
        "        WHERE directorid IN ({id_list_str})\n",
        "          AND gender IS NOT NULL AND dob IS NOT NULL\n",
        "    \"\"\"\n",
        "    chunk_df = db.raw_sql(query)\n",
        "    profile_chunks.append(chunk_df)\n",
        "\n",
        "profiles = pd.concat(profile_chunks, ignore_index=True)\n",
        "profiles[\"dateofbirth\"] = pd.to_datetime(profiles[\"dateofbirth\"], errors=\"coerce\")\n",
        "\n",
        "print(\"Computing diversity stats...\")\n",
        "directors = filtered_emp.merge(profiles, on=\"directorid\", how=\"inner\")\n",
        "directors[\"age_at_start\"] = (directors[\"emp_start\"] - directors[\"dateofbirth\"]).dt.days // 365\n",
        "\n",
        "agg_diversity = (\n",
        "    directors.groupby([\"companyid\", \"fiscal_year\"])\n",
        "    .agg(\n",
        "        num_directors=(\"directorid\", \"nunique\"),\n",
        "        pct_female=(\"gender\", lambda x: (x.str.upper() == \"FEMALE\").mean()),\n",
        "        num_female=(\"gender\", lambda x: (x.str.upper() == \"FEMALE\").sum()),\n",
        "        avg_age=(\"age_at_start\", \"mean\"),\n",
        "        stdev_age=(\"age_at_start\", \"std\"),\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "```\n",
        "\n",
        "## Step 6: Merge All Data\n",
        "\n",
        "``` python\n",
        "panel = link_table.copy()\n",
        "panel = panel.merge(boardex, on=[\"companyid\"], how=\"left\")\n",
        "panel = panel.merge(agg_diversity, on=[\"companyid\", \"fiscal_year\"], how=\"left\")\n",
        "panel = panel.merge(comp_funda, left_on=[\"gvkey\", \"fiscal_year\"], right_on=[\"gvkey\", \"fyear\"], how=\"left\").drop(columns=\"fyear\")\n",
        "```\n",
        "\n",
        "## Step 7: Output and Save\n",
        "\n",
        "``` python\n",
        "panel.to_csv(\"sp500_panel_full_with_diversity.csv\", index=False)\n",
        "print(\"âœ… Final dataset saved: sp500_panel_full_with_diversity.csv\")\n",
        "db.close()\n",
        "```\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Appendix\n",
        "\n",
        "::: {.callout-tip title=\"Data Sources\"}\n",
        "-   **BoardEx**: `na_board_characteristics`, `na_dir_profile_emp`, `na_dir_profile_details`\n",
        "-   **Compustat**: `funda`, `security`\n",
        "-   **Link Table**: `wrdsapps_link_crsp_comp_bdx.bdxcrspcomplink`\n",
        "-   **Ticker Universe**: Refinitiv tickers via JSON file\n",
        ":::\n",
        "\n",
        "::: {.callout-warning title=\"Reproducibility Tips\"}\n",
        "-   Always validate table existence with `db.list_tables('schema')`\n",
        "-   Validate available variables using `db.describe_table()` before querying\n",
        "-   Use `.drop_duplicates()` and `str.upper()` consistently for key merges\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "regression_env",
      "language": "python",
      "display_name": "Python (regression)",
      "path": "/Users/quinference/Library/Jupyter/kernels/regression_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}